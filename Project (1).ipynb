{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ZHlxa1Ijw8l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset into the dataframe\n",
        "df = pd.read_csv('/content/diabetic_data.csv')"
      ],
      "metadata": {
        "id": "tMOdL1NWmc22"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA**"
      ],
      "metadata": {
        "id": "Pr2mswhQyB-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Check the size of the dataset"
      ],
      "metadata": {
        "id": "OFOf_7gymlwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # Check the overall information"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0-nHs4lkm--0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum() # Check the missing values"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QmAz-A-EnhUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum() # Check the duplicate values"
      ],
      "metadata": {
        "id": "NMBw1OZ2nyEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.select_dtypes(include='object').columns:\n",
        "  print(df[i].value_counts())\n",
        "  print('---' * 10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6ebdkZKLoB-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T # Check the numerical data values"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kdykqNIOofN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram to understand the distribution, although i don't get anything üòÅ\n",
        "for i in df.select_dtypes(include='number').columns:\n",
        "  sns.histplot(data = df, x = i)\n",
        "  plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xjdBbJ_CpB5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age and Gender Count\n",
        "age_count = df[\"age\"].value_counts()\n",
        "gender_count = df[\"gender\"].value_counts()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "age_count.plot(kind='bar', ax=ax1, color='skyblue')\n",
        "gender_count.plot(kind='bar', ax=ax2, color='lightcoral')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Y1yk7CsOsFDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Race and Weight Count\n",
        "race_count = df[\"race\"].value_counts()\n",
        "weight_count = df[\"weight\"].value_counts()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "race_count.plot(kind='bar', ax=ax1, color='mediumseagreen')\n",
        "weight_count.plot(kind='bar', ax=ax2, color='goldenrod')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fcInxoa7tx4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Readmission Rate Count\n",
        "target_count = df['readmitted'].value_counts()\n",
        "target_count.plot(kind = 'bar', title= 'Readmission Count')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YzEHokaGq0-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "corr = df.select_dtypes(include = 'number').corr()\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IZ7v12Ruq4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns # To divide them into diagnosis_cols and"
      ],
      "metadata": {
        "id": "ie9RKJJ81cKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_cols = ['diag_1', 'diag_2', 'diag_3']\n",
        "\n",
        "# Diagnosis vs Readmission\n",
        "for diag in diagnosis_cols:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    top10 = df[diag].value_counts().iloc[:10].index  # Top 10 frequent diagnoses\n",
        "    sns.countplot(data=df[df[diag].isin(top10)], x=diag, hue='readmitted')\n",
        "    plt.title(f'{diag} vs Readmission')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xl7eaZQp190y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medication_cols = [\n",
        "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
        "    'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
        "    'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
        "    'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
        "    'glyburide-metformin', 'glipizide-metformin',\n",
        "    'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
        "    'metformin-pioglitazone'\n",
        "]\n",
        "\n",
        "# Medications vs Readmission\n",
        "for med in medication_cols:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(data=df, x=med, hue='readmitted')\n",
        "    plt.title(f'{med} Usage vs Readmission')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TqluVeSK2V_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Processing**"
      ],
      "metadata": {
        "id": "QyWmRHnW5lTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_info = []\n",
        "\n",
        "# Check missing values for object columns\n",
        "for col in df.select_dtypes(include = 'object').columns:\n",
        "        count_missing = df[col][df[col] == '?'].count()\n",
        "        percent_missing = (count_missing / df.shape[0] * 100).round(2)\n",
        "        missing_info.append([col, count_missing, percent_missing])\n",
        "\n",
        "# Create DataFrame from collected missing info\n",
        "missing_value = pd.DataFrame(missing_info, columns=[\"col\", \"count_missing\", \"percent_missing\"])\n",
        "missing_value = missing_value.sort_values(by=\"percent_missing\", ascending=False)\n",
        "\n",
        "missing_value"
      ],
      "metadata": {
        "id": "stRqkK4W5ueb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 3 columns with too many missing '?'\n",
        "df.drop(['weight', 'payer_code', 'medical_specialty'], axis=1, inplace=True)\n",
        "\n",
        "# Drop rows based on multiple cleaning conditions:\n",
        "df = df.drop(df[\n",
        "    # Drop if all three diagnosis columns are missing ('?')\n",
        "    ((df['diag_1'] == '?') & (df['diag_2'] == '?') & (df['diag_3'] == '?')) |\n",
        "\n",
        "    # Drop specific 'admission_type_id' values: 5 (Not Available), 6 (NULL), 8 (Not Mapped)\n",
        "    (df['admission_type_id'].isin([5, 6, 8])) |\n",
        "\n",
        "    # Drop 'discharge_disposition_id' values indicating death or irrelevant outcomes\n",
        "    (df['discharge_disposition_id'].isin([11, 13, 14, 18, 19, 20, 21, 25, 26])) |\n",
        "\n",
        "    # Drop 'admission_source_id' values that are unavailable, NULL, or not mapped\n",
        "    (df['admission_source_id'].isin([9, 15, 17, 20, 21]))\n",
        "].index)\n"
      ],
      "metadata": {
        "id": "62-qyZ2d6ry4"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Check th dimension now"
      ],
      "metadata": {
        "id": "LyGU9KV28tzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values in gender\n",
        "df = df.drop(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
        "\n",
        "# Drop missing values in race\n",
        "df = df.drop(set(df['race'][df['race']=='?'].index))"
      ],
      "metadata": {
        "id": "VSg2keZX_NHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Check th dimension now"
      ],
      "metadata": {
        "id": "Ygy7AcWLAMQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant variables\n",
        "df = df.drop([\"encounter_id\",\"patient_nbr\"],axis=1)\n",
        "df = df.drop([\"citoglipton\",\"examide\"],axis = 1)"
      ],
      "metadata": {
        "id": "C5G9YjdfCbPQ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Check th dimension now"
      ],
      "metadata": {
        "id": "s6Sj32TlCk0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['readmitted'].value_counts() # Just to check the difference"
      ],
      "metadata": {
        "id": "6LoBf9pbKRDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "afQ_tDIzMBuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop max_glu_serum because it's almost entirely missing\n",
        "df.drop('max_glu_serum', axis=1, inplace=True)\n",
        "\n",
        "# Fill A1Cresult missing values with 'None'\n",
        "df['A1Cresult'] = df['A1Cresult'].fillna('None')"
      ],
      "metadata": {
        "id": "58qQ1syuNIVq"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Check th dimension now"
      ],
      "metadata": {
        "id": "qiSpBEjyNLB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoding IDs using mapping file\n",
        "admission_type_map = {\n",
        "    1: 'Emergency',\n",
        "    2: 'Urgent',\n",
        "    3: 'Elective',\n",
        "    4: 'Newborn',\n",
        "    7: 'Trauma Center',\n",
        "}\n",
        "\n",
        "discharge_disposition_map = {\n",
        "    1: 'Discharged to home',\n",
        "    2: 'Discharged/transferred to another short term hospital',\n",
        "    3: 'Discharged/transferred to SNF',\n",
        "    4: 'Discharged/transferred to ICF',\n",
        "    5: 'Discharged/transferred to another type of inpatient care institution',\n",
        "    6: 'Discharged/transferred to home with home health service',\n",
        "    7: 'Left AMA',\n",
        "    8: 'Discharged/transferred to home under care of Home IV provider',\n",
        "    9: 'Admitted as an inpatient to this hospital',\n",
        "    10: 'Neonate discharged to another hospital for neonatal aftercare',\n",
        "    12: 'Still patient or expected to return for outpatient services',\n",
        "    15: 'Discharged/transferred within this institution to Medicare approved swing bed',\n",
        "    16: 'Discharged/transferred/referred another institution for outpatient services',\n",
        "    17: 'Discharged/transferred to a psychiatric hospital of psychiatric distinct part unit of a hospital',\n",
        "    22: 'Discharged/transferred to another rehab facility including rehab units of a hospital',\n",
        "    23: 'Discharged/transferred to a long term care hospital',\n",
        "    24: 'Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare',\n",
        "}\n",
        "\n",
        "admission_source_map = {\n",
        "    1: 'Physician Referral',\n",
        "    2: 'Clinic Referral',\n",
        "    3: 'HMO Referral',\n",
        "    4: 'Transfer from a hospital',\n",
        "    5: 'Transfer from a Skilled Nursing Facility (SNF)',\n",
        "    6: 'Transfer from another health care facility',\n",
        "    7: 'Emergency Room',\n",
        "    8: 'Court/Law Enforcement',\n",
        "    10: 'Transfer from critical access hospital',\n",
        "    11: 'Normal Delivery',\n",
        "    12: 'Premature Delivery',\n",
        "    13: 'Sick Baby',\n",
        "    14: 'Extramural Birth',\n",
        "}\n",
        "\n",
        "df['admission_type_id'] = df['admission_type_id'].replace(admission_type_map)\n",
        "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(discharge_disposition_map)\n",
        "df['admission_source_id'] = df['admission_source_id'].replace(admission_source_map)"
      ],
      "metadata": {
        "id": "s3LHYHQ1Pat8"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding some important features\n",
        "df['total_visits'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
        "df['missing_diag'] = ((df['diag_1'] == '?') | (df['diag_2'] == '?') | (df['diag_3'] == '?')).astype(int)\n",
        "\n",
        "# List of medication columns\n",
        "meds_cols = [\n",
        "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
        "    'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide',\n",
        "    'metformin-pioglitazone', 'metformin-rosiglitazone', 'glimepiride-pioglitazone',\n",
        "    'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide'\n",
        "]\n",
        "\n",
        "# Create new binary columns: 1 if med was changed (up or down), 0 if no change or steady (Some encoding)\n",
        "for col in meds_cols:\n",
        "    new_col = f\"{col}_new\"\n",
        "    df[new_col] = df[col].apply(lambda x: 0 if x in ['No', 'Steady'] else 1)\n",
        "\n",
        "# Sum up all the med changes to create a 'med_change' feature\n",
        "df['med_change'] = df[[f\"{col}_new\" for col in meds_cols]].sum(axis=1)\n",
        "\n",
        "# Drop the temporary binary columns\n",
        "df.drop(columns=[f\"{col}_new\" for col in meds_cols], inplace=True)"
      ],
      "metadata": {
        "id": "tY0n2bSRQDod"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['med_change'].value_counts()"
      ],
      "metadata": {
        "id": "KYRiSyvcRClk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recode medication columns: 'No' ‚Üí 0, all others ('Steady', 'Up', 'Down') ‚Üí 1\n",
        "for col in meds_cols:\n",
        "    df[col] = df[col].replace({'No': 0, 'Steady': 1, 'Up': 1, 'Down': 1})\n",
        "\n",
        "# Create 'num_med' feature: sum across the medication columns\n",
        "df['num_med'] = df[meds_cols].sum(axis=1)"
      ],
      "metadata": {
        "id": "KIzF-x3qR51S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_med'].value_counts()"
      ],
      "metadata": {
        "id": "cg9po1_fSEKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the outcome variable readmission\n",
        "df['readmitted'] = df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)"
      ],
      "metadata": {
        "id": "LuYXhzpXSq6t"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Age\n",
        "df['age_num'] = df['age'].str.extract('(\\d+)', expand=False).astype(int) + 5"
      ],
      "metadata": {
        "id": "cIxeX_5gS1lP"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age_num'].value_counts()"
      ],
      "metadata": {
        "id": "UuxsI7DvS-bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "4lPMf26BUD0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['high_A1C_flag'] = df['A1Cresult'].isin(['>7', '>8']).astype(int)"
      ],
      "metadata": {
        "id": "-W5GJLlPWKxh"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Label Encode 'race', 'A1Cresult', 'max_glu_serum'\n",
        "label_cols = ['race', 'A1Cresult']\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "XX2XT55qT1TP"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diag_1'].value_counts()"
      ],
      "metadata": {
        "id": "sZbDqxSrXQqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Safe numeric conversion first\n",
        "df['diag_1_num'] = pd.to_numeric(df['diag_1'], errors='coerce')\n",
        "df['diag_2_num'] = pd.to_numeric(df['diag_2'], errors='coerce')\n",
        "df['diag_3_num'] = pd.to_numeric(df['diag_3'], errors='coerce')\n",
        "\n",
        "# Initialize new columns\n",
        "df['diag_1_code'] = 0\n",
        "df['diag_2_code'] = 0\n",
        "df['diag_3_code'] = 0\n",
        "\n",
        "# Mapping for diag_1\n",
        "df.loc[df['diag_1'].astype(str).str.startswith('V'), 'diag_1_code'] = 1\n",
        "df.loc[df['diag_1'].astype(str).str.startswith('E'), 'diag_1_code'] = 2\n",
        "df.loc[((df['diag_1_num'] >= 390) & (df['diag_1_num'] < 460)) | (df['diag_1_num'] == 785), 'diag_1_code'] = 3\n",
        "df.loc[((df['diag_1_num'] >= 460) & (df['diag_1_num'] < 520)) | (df['diag_1_num'] == 786), 'diag_1_code'] = 4\n",
        "df.loc[((df['diag_1_num'] >= 520) & (df['diag_1_num'] < 580)) | (df['diag_1_num'] == 787), 'diag_1_code'] = 5\n",
        "df.loc[(df['diag_1_num'] >= 250) & (df['diag_1_num'] < 251), 'diag_1_code'] = 6\n",
        "df.loc[(df['diag_1_num'] >= 800) & (df['diag_1_num'] < 1000), 'diag_1_code'] = 7\n",
        "df.loc[(df['diag_1_num'] >= 710) & (df['diag_1_num'] < 740), 'diag_1_code'] = 8\n",
        "df.loc[((df['diag_1_num'] >= 580) & (df['diag_1_num'] < 630)) | (df['diag_1_num'] == 788), 'diag_1_code'] = 9\n",
        "df.loc[(df['diag_1_num'] >= 140) & (df['diag_1_num'] < 240), 'diag_1_code'] = 10\n",
        "\n",
        "# Mapping for diag_2\n",
        "df.loc[df['diag_2'].astype(str).str.startswith('V'), 'diag_2_code'] = 1\n",
        "df.loc[df['diag_2'].astype(str).str.startswith('E'), 'diag_2_code'] = 2\n",
        "df.loc[((df['diag_2_num'] >= 390) & (df['diag_2_num'] < 460)) | (df['diag_2_num'] == 785), 'diag_2_code'] = 3\n",
        "df.loc[((df['diag_2_num'] >= 460) & (df['diag_2_num'] < 520)) | (df['diag_2_num'] == 786), 'diag_2_code'] = 4\n",
        "df.loc[((df['diag_2_num'] >= 520) & (df['diag_2_num'] < 580)) | (df['diag_2_num'] == 787), 'diag_2_code'] = 5\n",
        "df.loc[(df['diag_2_num'] >= 250) & (df['diag_2_num'] < 251), 'diag_2_code'] = 6\n",
        "df.loc[(df['diag_2_num'] >= 800) & (df['diag_2_num'] < 1000), 'diag_2_code'] = 7\n",
        "df.loc[(df['diag_2_num'] >= 710) & (df['diag_2_num'] < 740), 'diag_2_code'] = 8\n",
        "df.loc[((df['diag_2_num'] >= 580) & (df['diag_2_num'] < 630)) | (df['diag_2_num'] == 788), 'diag_2_code'] = 9\n",
        "df.loc[(df['diag_2_num'] >= 140) & (df['diag_2_num'] < 240), 'diag_2_code'] = 10\n",
        "\n",
        "# Mapping for diag_3\n",
        "df.loc[df['diag_3'].astype(str).str.startswith('V'), 'diag_3_code'] = 1\n",
        "df.loc[df['diag_3'].astype(str).str.startswith('E'), 'diag_3_code'] = 2\n",
        "df.loc[((df['diag_3_num'] >= 390) & (df['diag_3_num'] < 460)) | (df['diag_3_num'] == 785), 'diag_3_code'] = 3\n",
        "df.loc[((df['diag_3_num'] >= 460) & (df['diag_3_num'] < 520)) | (df['diag_3_num'] == 786), 'diag_3_code'] = 4\n",
        "df.loc[((df['diag_3_num'] >= 520) & (df['diag_3_num'] < 580)) | (df['diag_3_num'] == 787), 'diag_3_code'] = 5\n",
        "df.loc[(df['diag_3_num'] >= 250) & (df['diag_3_num'] < 251), 'diag_3_code'] = 6\n",
        "df.loc[(df['diag_3_num'] >= 800) & (df['diag_3_num'] < 1000), 'diag_3_code'] = 7\n",
        "df.loc[(df['diag_3_num'] >= 710) & (df['diag_3_num'] < 740), 'diag_3_code'] = 8\n",
        "df.loc[((df['diag_3_num'] >= 580) & (df['diag_3_num'] < 630)) | (df['diag_3_num'] == 788), 'diag_3_code'] = 9\n",
        "df.loc[(df['diag_3_num'] >= 140) & (df['diag_3_num'] < 240), 'diag_3_code'] = 10\n",
        "\n",
        "# Optional: Drop intermediate numeric columns if you want\n",
        "df.drop(['diag_1_num', 'diag_2_num', 'diag_3_num'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "_udccVmsZzyV"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diag_1_code'].value_counts()"
      ],
      "metadata": {
        "id": "ij-3tIcGac0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "vXauPiX1awbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "N1uSAuYZbYiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_col = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\n",
        "num_col"
      ],
      "metadata": {
        "id": "EvO8kunzdAkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(data):\n",
        "    return ((data - np.mean(data, axis = 0)) / np.std(data, axis = 0))\n",
        "# num_col is a list of all numeric features\n",
        "df[num_col] = standardize(df[num_col])"
      ],
      "metadata": {
        "id": "gk2-WAG7coGu"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle outliers for all numerical columns\n",
        "\n",
        "for col in num_col:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Clip the outliers\n",
        "    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)"
      ],
      "metadata": {
        "id": "Cceqj8fRd5eP"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "sEDsMr5pd94C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "0YFoCnfPeQmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns that are categorical (object type) and need encoding\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Apply LabelEncoder to each categorical column\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))"
      ],
      "metadata": {
        "id": "KR-rDWVSech2"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['readmitted'].value_counts()"
      ],
      "metadata": {
        "id": "Wr4FcZbpgfI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum() # high_A1C_flag, metformin-rosiglitazone"
      ],
      "metadata": {
        "id": "CH535EHhgtBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['metformin-rosiglitazone', 'high_A1C_flag'], axis = 1)"
      ],
      "metadata": {
        "id": "Hi1j-DTYg5OI"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test just see if all of the above came with profit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Split features and target\n",
        "x = df.drop('readmitted', axis=1)\n",
        "y = df['readmitted']\n",
        "\n",
        "# Stratified train-test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n",
        "\n",
        "# Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print all results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SRc7zwegpcw",
        "outputId": "973c0d5d-f535-434d-d4e4-2316c9d6e9ca"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6572174335316255\n",
            "Precision: 0.17575966850828728\n",
            "Recall: 0.5383395029085141\n",
            "F1 Score: 0.26500065078745283\n",
            "Confusion Matrix:\n",
            " [[9809 4774]\n",
            " [ 873 1018]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.67      0.78     14583\n",
            "           1       0.18      0.54      0.27      1891\n",
            "\n",
            "    accuracy                           0.66     16474\n",
            "   macro avg       0.55      0.61      0.52     16474\n",
            "weighted avg       0.83      0.66      0.72     16474\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}